# Ray クラスター設定例
# このファイルをコピーして config.yaml として保存し、必要に応じて編集してください

project:
  name: cslr-exp-platform
  version: 0.1.0

host:
  has_gpu: true  # GPU が利用可能な場合は true
  # gpu_type: nvidia  # GPU タイプ (nvidia, amd)。未指定時は自動検出
  # hostname: localhost  # ホスト名。未指定時はデフォルト値
  # ip_address: null  # ホスト IP アドレス。未指定時は自動検出

network:
  subnet: 172.28.0.0/16

nodes:
  head_whitelist:
    - ray-cpu
    - ray-gpu
  head_address: null
  health_service:
    url: "http://health:8080"
    timeout: 1
    max_retries: 3
    retry_interval: 0.5
  cluster:
    discovery_timeout: 5
    wait_for_head: 30

volumes:
  mlflow_data: ./data/mlflow
  postgres_data: ./data/postgres

cluster_test:
  target: cpu  # cpu / gpu
  test_network_subnet: 172.30.0.0/24
  worker_node_manager_port: 30000
  worker_object_manager_port: 30001
  worker_min_worker_port: 30010
  worker_max_worker_port: 30020
  worker_cpu_node_manager_port: 30100
  worker_cpu_object_manager_port: 30101
  worker_cpu_min_worker_port: 30110
  worker_cpu_max_worker_port: 30120

services:
  # ヘルスチェック用サービス
  health:
    enabled: true
    port: 8888

  # Ray クラスター設定
  ray:
    # 共通設定（フォールバック）: cpu.image / gpu.image が未指定の場合に適用
    # 運用では cpu.image / gpu.image の個別指定を推奨
    # CPU/GPU の同時起動は cluster_test（検証用途）に限定
    # 公式イメージを使用する場合
    # image: rayproject/ray:latest
    # カスタムイメージをビルドする場合
    image: cslr-exp-platform:ray-runtime
    build:
      enabled: true
      dockerfile: ../Dockerfile
      target: ray-runtime
      context: ..

    # CPU ヘッドノード
    cpu:
      enabled: true
      cpus: 4
      memory: 8g
      head_port: 6379
      dashboard_port: 8265
      client_port: 20001
      # node_ip_address: null
      # node_manager_port: 30000
      # object_manager_port: 30001
      # min_worker_port: 30010
      # max_worker_port: 30020

    # GPU ヘッドノード
    gpu:
      enabled: true
      cpus: 4
      memory: 16g
      head_port: 6380
      dashboard_port: 8266
      client_port: 20002
      # node_ip_address: null
      # node_manager_port: 31000
      # object_manager_port: 31001
      # min_worker_port: 31010
      # max_worker_port: 31020

  # Redis サービス
  redis:
    enabled: true
    image: redis:7-alpine
    port: 6381

  # MLflow サービス
  mlflow:
    enabled: true
    image: ghcr.io/mlflow/mlflow:latest
    port: 5000
    postgres:
      enabled: true
      image: postgres:16-alpine
      user: mlflow
      password: CHANGE_ME_INVALID_PASSWORD  # 必須: .env または環境変数で上書き
      database: mlflow

  # Marimo サービス
  marimo:
    enabled: true
    # 公式イメージを使用: image: "marimo-labs/marimo:latest"
    # カスタムイメージをビルド: image: "cslr-exp-platform:marimo-runtime"
    image: "cslr-exp-platform:marimo-runtime"
    build:
      enabled: true
      dockerfile: "../Dockerfile"
      target: "marimo-runtime"
      context: ".."
    port: 8080

# ネットワーク構成:
# ray-network (172.28.0.0/16) 上に全サービスを配置
# - Ray ヘッドノード (CPU/GPU)
# - Redis, MLflow, Postgres, Marimo
# - 内部サービスは相互にアクセス可能
